from langchain.schema import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

class OpenAiModel:
    """
    Class for interacting with the OpenAI model, allowing message sending
    and receiving of processed responses.

    Attributes:
        model (ChatOpenAI): Instance of the OpenAI chat model configured with the model name, API key, and temperature.
    """

   
    def __init__(self, model_name, key, temperature=0.5):
        """
        Initializes the OpenAiModel class with the necessary configuration for the OpenAI model.

        Args:
            model_name (str): Name of the OpenAI model to be used (e.g., "gpt-4o-mini").
            key (str): API key for OpenAI authentication. Loaded from the .env file.
            temperature (float, optional): Degree of randomness in the model's responses.
                                        Lower values make responses more deterministic.
                                        Default is 0.5.
        """
        self.model = ChatOpenAI(temperature=temperature, model_name=model_name, openai_api_key=key)

    def talk_to_model(self, system_message, human_message):
        """
        Sends messages to the OpenAI model and returns the generated response.

        Args:
            system_message (str): System message that defines the context or instructions for the model.
            human_message (str): Message sent by the user or human interacting with the model.

        Returns:
            str: Content of the response generated by the OpenAI model.
        """

        messages = [
            SystemMessage(
                content=system_message
            ),
            HumanMessage(
                content=human_message
            )
        ]
        return self.model(messages).content